{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1076a0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from qdrant_client import QdrantClient, models  \n",
    "from metadata_registry import FILE_METADATA, DEFAULT_METADATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c6f1d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMStudioBgeM3Dense:\n",
    "    def __init__(self, base_url, model):\n",
    "        self.url = f\"{base_url}/embeddings\"\n",
    "        self.model = model\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        r = requests.post(\n",
    "            self.url,\n",
    "            json={\n",
    "                \"model\": self.model,\n",
    "                \"input\": texts  # MUST be raw strings\n",
    "            }\n",
    "        )\n",
    "        r.raise_for_status()\n",
    "        return [d[\"embedding\"] for d in r.json()[\"data\"]]\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        return self.embed_documents([text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01bfe506",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = LMStudioBgeM3Dense(\n",
    "    base_url=\"http://127.0.0.1:1234/v1\",\n",
    "    model=\"text-embedding-bge-m3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d36edd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n"
     ]
    }
   ],
   "source": [
    "print(len(embedder.embed_query(\"test sentence\")))  # must be 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4b0d733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_markdown_unified(md_text):\n",
    "    lines = md_text.split(\"\\n\")\n",
    "    parsed = []\n",
    "\n",
    "    section = \"General\"\n",
    "    headers = []\n",
    "    in_table = False\n",
    "\n",
    "    for line in lines:\n",
    "        s = line.strip()\n",
    "        if not s:\n",
    "            continue\n",
    "\n",
    "        if s.startswith(\"#\"):\n",
    "            section = s.lstrip(\"#\").strip()\n",
    "            in_table = False\n",
    "            continue\n",
    "\n",
    "        if \"|\" in s and \"---\" not in s:\n",
    "            cells = [c.strip() for c in s.split(\"|\") if c.strip()]\n",
    "            if not in_table:\n",
    "                headers = cells\n",
    "                in_table = True\n",
    "            elif len(cells) == len(headers):\n",
    "                parsed.append({\n",
    "                    \"type\": \"table_row\",\n",
    "                    \"section\": section,\n",
    "                    \"data\": dict(zip(headers, cells))\n",
    "                })\n",
    "            continue\n",
    "\n",
    "        if not in_table:\n",
    "            parsed.append({\n",
    "                \"type\": \"text_block\",\n",
    "                \"section\": section,\n",
    "                \"text\": s\n",
    "            })\n",
    "\n",
    "    return parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83e28a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"http://127.0.0.1:1234/v1\",\n",
    "    api_key=\"not-needed\",\n",
    "    model=\"meta-llama-3.1-8b-instruct\",\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "def describe_table_row(section, row):\n",
    "    data = \", \".join(f\"{k}: {v}\" for k, v in row.items())\n",
    "    prompt = f\"Convert this table row into one factual sentence.\\nSection: {section}\\nRow: {data}\"\n",
    "    try:\n",
    "        return llm.invoke(prompt).content.strip()\n",
    "    except:\n",
    "        return f\"In {section}, {data}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1d724d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM response: OK\n"
     ]
    }
   ],
   "source": [
    "resp = llm.invoke(\"Say only the word: OK\")\n",
    "print(\"LLM response:\", resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "178b8e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = QdrantClient(\n",
    "    url=\"http://localhost:6333\",\n",
    "    timeout=120)\n",
    "collection = \"md_bge_m3_source\"\n",
    "\n",
    "if client.collection_exists(collection):\n",
    "    client.delete_collection(collection)\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=collection,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=1024,\n",
    "        distance=models.Distance.COSINE\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acfbcca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched(iterable, size):\n",
    "    for i in range(0, len(iterable), size):\n",
    "        yield iterable[i:i + size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b0fb78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata_for_file(filename: str) -> dict:\n",
    "    return FILE_METADATA.get(filename, DEFAULT_METADATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0436199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_markdown_file(md_path: str, embed_batch_size=16, upsert_batch_size=64):\n",
    "    meta = get_metadata_for_file(Path(md_path).name)\n",
    "    \n",
    "    with open(md_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    items = parse_markdown_unified(content)\n",
    "\n",
    "    texts, payloads = [], []\n",
    "\n",
    "    for i, item in enumerate(items):\n",
    "        chunk_id = f\"{Path(md_path).stem}_{i}\"\n",
    "\n",
    "        if item[\"type\"] == \"table_row\":\n",
    "            text = describe_table_row(item[\"section\"], item[\"data\"])\n",
    "            payload = {\n",
    "                \"source_file\": Path(md_path).name,\n",
    "                \"section\": item[\"section\"],\n",
    "                \"type\": \"table\",\n",
    "                \"chunk_id\": chunk_id,\n",
    "                **item[\"data\"],\n",
    "                \n",
    "                # dynamic metadata\n",
    "                \"doc_type\": meta.get(\"doc_type\"),\n",
    "                \"category\": meta.get(\"category\"),\n",
    "                \"jurisdiction\": meta.get(\"jurisdiction\"),\n",
    "                \"authority\": meta.get(\"authority\"),\n",
    "                \n",
    "            }\n",
    "        else:\n",
    "            text = f\"Context: {item['section']}. Content: {item['text']}\"\n",
    "            payload = {\n",
    "                \"source_file\": Path(md_path).name,\n",
    "                \"section\": item[\"section\"],\n",
    "                \"type\": \"text\",\n",
    "                \"chunk_id\": chunk_id,\n",
    "                \"original_text\": item[\"text\"],\n",
    "\n",
    "                # dynamic metadata\n",
    "                \"doc_type\": meta.get(\"doc_type\"),\n",
    "                \"category\": meta.get(\"category\"),\n",
    "                \"jurisdiction\": meta.get(\"jurisdiction\"),\n",
    "                \"authority\": meta.get(\"authority\"),\n",
    "            }\n",
    "\n",
    "        texts.append(text)\n",
    "        payloads.append(payload)\n",
    "\n",
    "    # ---- EMBEDDING (BATCHED) ----\n",
    "    all_vectors = []\n",
    "    for batch in batched(texts, embed_batch_size):\n",
    "        all_vectors.extend(embedder.embed_documents(batch))\n",
    "\n",
    "    # ---- UPSERT (BATCHED) ----\n",
    "    points = [\n",
    "        models.PointStruct(\n",
    "            id=str(uuid.uuid4()),\n",
    "            vector=all_vectors[i],\n",
    "            payload=payloads[i]\n",
    "        )\n",
    "        for i in range(len(all_vectors))\n",
    "    ]\n",
    "\n",
    "    for batch in batched(points, upsert_batch_size):\n",
    "        client.upsert(\n",
    "            collection_name=collection,\n",
    "            points=batch\n",
    "        )\n",
    "\n",
    "    print(f\"Ingested safely: {md_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3f7ada9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34 markdown files\n",
      "Ingested safely: source_of_truth_markdowns\\Bharatiya Sakshya Adhiniyam (BSA), 2023.md\n",
      "Ingested safely: source_of_truth_markdowns\\BNS.md\n",
      "Ingested safely: source_of_truth_markdowns\\BNSS.md\n",
      "Ingested safely: source_of_truth_markdowns\\budget_2025-2026.md\n",
      "Ingested safely: source_of_truth_markdowns\\Charter of Patients Rights (NHRC).md\n",
      "Ingested safely: source_of_truth_markdowns\\Code on Wages, 2019.md\n",
      "Ingested safely: source_of_truth_markdowns\\CONSTITUTION_OF_INDIA.md\n",
      "Ingested safely: source_of_truth_markdowns\\Consumer Protection Act, 2019.md\n",
      "Ingested safely: source_of_truth_markdowns\\DPDP Act, 2023.md\n",
      "Ingested safely: source_of_truth_markdowns\\GST Acts (CGST SGST).md\n",
      "Ingested safely: source_of_truth_markdowns\\Income Tax Act, 1961.md\n",
      "Ingested safely: source_of_truth_markdowns\\Industrial Disputes Act, 1947.md\n",
      "Ingested safely: source_of_truth_markdowns\\IT Act, 2000.md\n",
      "Ingested safely: source_of_truth_markdowns\\Lokpal and Lokayuktas Act, 2013.md\n",
      "Ingested safely: source_of_truth_markdowns\\Maintenance and Welfare of Parents Act.md\n",
      "Ingested safely: source_of_truth_markdowns\\Maternity Benefit Act, 1961.md\n",
      "Ingested safely: source_of_truth_markdowns\\Mental Healthcare Act, 2017.md\n",
      "Ingested safely: source_of_truth_markdowns\\Model Tenancy Act, 2021.md\n",
      "Ingested safely: source_of_truth_markdowns\\Motor Vehicles (Amendment) Act, 2019.md\n",
      "Ingested safely: source_of_truth_markdowns\\MTP Act, 1971 (Amended).md\n",
      "Ingested safely: source_of_truth_markdowns\\National Highways Act and Fee Rules.md\n",
      "Ingested safely: source_of_truth_markdowns\\Negotiable Instruments Act, 1881.md\n",
      "Ingested safely: source_of_truth_markdowns\\POCSO Act, 2012.md\n",
      "Ingested safely: source_of_truth_markdowns\\POSH Act, 2013.md\n",
      "Ingested safely: source_of_truth_markdowns\\PREVENTION_OF_CORRUPTION_ACT_1988.md\n",
      "Ingested safely: source_of_truth_markdowns\\PWDVA Act, 2005 (Domestic Violence).md\n",
      "Ingested safely: source_of_truth_markdowns\\RBI Integrated Ombudsman Scheme.md\n",
      "Ingested safely: source_of_truth_markdowns\\RBI Master Circular (Customer Service).md\n",
      "Ingested safely: source_of_truth_markdowns\\RERA Act, 2016.md\n",
      "Ingested safely: source_of_truth_markdowns\\Rights of PWD Act, 2016.md\n",
      "Ingested safely: source_of_truth_markdowns\\RTI_ACT_2005.md\n",
      "Ingested safely: source_of_truth_markdowns\\SC ST (Prevention of Atrocities) Act.md\n",
      "Ingested safely: source_of_truth_markdowns\\Transfer of Property Act, 1882.md\n",
      "Ingested safely: source_of_truth_markdowns\\Whistleblowers Protection Act, 2014.md\n"
     ]
    }
   ],
   "source": [
    "MARKDOWN_DIR = \"source_of_truth_markdowns\"  # folder containing all your .md files\n",
    "\n",
    "md_files = list(Path(MARKDOWN_DIR).glob(\"*.md\"))\n",
    "\n",
    "print(f\"Found {len(md_files)} markdown files\")\n",
    "\n",
    "for md_file in md_files:\n",
    "    ingest_markdown_file(str(md_file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
